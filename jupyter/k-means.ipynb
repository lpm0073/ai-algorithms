{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gKAjgYiDMQn"
   },
   "source": [
    "# K-means Clustering on the Iris Dataset\n",
    "\n",
    "This notebook demonstrates how to perform K-means clustering on the classic Iris dataset using Python, scikit-learn, and Google Colab.  \n",
    "K-means is an unsupervised machine learning algorithm that groups data into clusters based on feature similarity.\n",
    "\n",
    "**In this notebook, you will:**\n",
    "- Load the Iris dataset directly from the UCI Machine Learning Repository\n",
    "- Apply K-means clustering to group the data into clusters\n",
    "- Visualize the resulting clusters\n",
    "\n",
    "No prior setup or downloads are required—simply run each cell to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages and enable ipywidgets for progress bars\n",
    "%pip install ipywidgets pandas scikit-learn matplotlib shap\n",
    "\n",
    "# Enable ipywidgets extension (for classic Jupyter Notebook only)\n",
    "%jupyter nbextension enable --py widgetsnbextension\n",
    "%jupyter nbextension install --py widgetsnbextension\n",
    "\n",
    "# Download the House Prices dataset from Kaggle\n",
    "!kaggle competitions download -c house-prices-advanced-regression-techniques\n",
    "!unzip -q house-prices-advanced-regression-techniques.zip -d house_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ca52XxqOEC78"
   },
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "\n",
    "import pandas as pd                 # https://pandas.pydata.org/docs/\n",
    "from sklearn.cluster import KMeans  # https://sklearn-features.readthedocs.io/en/stable/\n",
    "import matplotlib.pyplot as plt     # https://matplotlib.org/stable/index.html\n",
    "import shap                         # https://shap.readthedocs.io/en/latest/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Iris dataset from UC Irvine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "cols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "df = pd.read_csv(url, header=None, names=cols)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare data (drop species column for clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('species', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize clusters (using first two features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['sepal_length'], df['sepal_width'], c=df['cluster'])\n",
    "plt.xlabel('Sepal Length')\n",
    "plt.ylabel('Sepal Width')\n",
    "plt.title('K-means Clusters on Iris Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Interpreting Results\n",
    "\n",
    "### Expected results\n",
    "\n",
    "- Red dots are 'high features' (ie, a flower with long petals or wide sepals) whereas blue dots are 'low features' (ie, a flower with short petals or narrow sepals).\n",
    "- Petal length is the most powerful feature for separating flowers into clusters — consistent with biology (Setosa has short petals).\n",
    "- SHAP confirms that the clustering model primarily uses petal-related features to group the Iris species.\n",
    "- Clusters likely correspond well with the natural species grouping: Setosa, Versicolor, and Virginica.\n",
    "\n",
    "Each dot is a data point (a flower), and the position on the x-axis shows how much a feature influenced the model’s decision to assign that point to a particular cluster:\n",
    "\n",
    "1. petal_length has the strongest influence overall:\n",
    "- Low petal length (blue) pushes the SHAP value left — strong influence toward one cluster (likely Setosa, which has short petals).\n",
    "- High petal length (red) pushes SHAP values right, indicating a pull toward a different cluster (likely Virginica).\n",
    "\n",
    "2. sepal_length also plays an important role:\n",
    "- Higher sepal lengths (pink/red) increase SHAP values — influence toward a cluster with longer sepals.\n",
    "- Lower sepal lengths (blue) reduce SHAP impact, pulling the data toward a different group.\n",
    "\n",
    "3. petal_width is moderately important:\n",
    "- Mostly contributes to negative SHAP values when small (blue), influencing Setosa classification again.\n",
    "- Larger widths push toward another cluster.\n",
    "\n",
    "4. sepal_width has the least impact:\n",
    "- Its SHAP values are tightly centered around 0.\n",
    "- While it may help fine-tune cluster assignments, it isn’t a major driver of separation.\n",
    "\n",
    "### Understanding your dataset quality\n",
    "\n",
    "#### Good dataset (like this one)\n",
    "\n",
    "Red and blue dots (high and low values) are clustered consistently on different sides of the SHAP axis for important features. This is what you should see in the Iris dataset.\n",
    "\n",
    "#### Warning signs of a bad dataset\n",
    "\n",
    "Contrastingly, if the Iris dataset were of poor quality, a SHAP plot might look like:\n",
    "- All SHAP values close to zero\n",
    "- Red and blue dots randomly spread left/right. This means the model doesn’t know whether a high or low value increases or decreases the cluster assignment, which would be a sign that the feature isn’t informative, possibly due to noise or label issues.\n",
    "- No obvious dominant feature\n",
    "- Features that shouldn’t matter (based on intuition) appear at the top\n",
    "\n",
    "- SHAP Values Near Zero for All Features. If all the dots cluster close to 0 for most features, it means:\n",
    "  - The model didn’t find any feature particularly helpful for clustering.\n",
    "  - This may happen if the features are noisy, corrupted, or irrelevant.\n",
    "  - For example: swapped columns, measurement errors, or missing data filled incorrectly.\n",
    "\n",
    "- Important Features Are Missing\n",
    "  - If you expected petal_length and petal_width to dominate (as in clean Iris data), but instead you see:\n",
    "  - sepal_width or a meaningless feature like row_id at the top,\n",
    "  - that suggests the real informative features were damaged or removed during preprocessing.\n",
    "\n",
    "- Too Much Variation Within a Feature. For a specific feature:\n",
    "  - If both red and blue dots appear on both sides of the SHAP axis without a clear pattern, the model is probably confused.\n",
    "  - That could mean inconsistent labels, overlapping distributions, or non-standardized input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP expects a model with a predict method; for clustering, we can use the KMeans object.\n",
    "explainer = shap.Explainer(kmeans.predict, X)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# Visualize SHAP values for the first cluster\n",
    "shap.summary_plot(shap_values, X, show=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOUYrjEYAVUpeNCP4+c07lo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv3.12 (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
